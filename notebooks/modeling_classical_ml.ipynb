{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fab0793",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34bc90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender before mapping: ['Female' 'Male']\n",
      "gender after mapping: <IntegerArray>\n",
      "[<NA>]\n",
      "Length: 1, dtype: Int64\n",
      "MultipleLines before mapping: ['No' 'Yes']\n",
      "MultipleLines after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n",
      "OnlineSecurity before mapping: ['No' 'Yes']\n",
      "OnlineSecurity after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n",
      "OnlineBackup before mapping: ['Yes' 'No']\n",
      "OnlineBackup after mapping: <IntegerArray>\n",
      "[1, 0]\n",
      "Length: 2, dtype: Int64\n",
      "DeviceProtection before mapping: ['No' 'Yes']\n",
      "DeviceProtection after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n",
      "TechSupport before mapping: ['No' 'Yes']\n",
      "TechSupport after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n",
      "StreamingTV before mapping: ['No' 'Yes']\n",
      "StreamingTV after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n",
      "StreamingMovies before mapping: ['No' 'Yes']\n",
      "StreamingMovies after mapping: <IntegerArray>\n",
      "[0, 1]\n",
      "Length: 2, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # Added missing imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "class AddFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.autopay_methods = ['Bank transfer (automatic)', 'Credit card (automatic)']\n",
    "        self.contract_durations = {'Month-to-month': 1, 'One year': 12, 'Two year': 24}\n",
    "        self.output_columns_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # X.drop(columns=['gender'], inplace=True)\n",
    "        #Tenure group\n",
    "        X['tenure_group'] = pd.cut(X['tenure'], bins=[0, 6, 12, 24, 48, 60, 72], \n",
    "                                  labels=['0–6', '6–12', '12–24', '24–48', '48–60', '60–72'])\n",
    "        X['new_customer'] = (X['tenure_group'] == '0–6').astype(int)\n",
    "        #Payment and add-on features\n",
    "        X['is_autopay'] = X['PaymentMethod'].apply(lambda x: 1 if x in self.autopay_methods else 0)\n",
    "        X['AddOnCount'] = (X[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                              'TechSupport', 'StreamingTV', 'StreamingMovies']] == 'Yes').sum(axis=1)\n",
    "        X['AddOnGroup'] = pd.cut(X['AddOnCount'], bins=[-1, 0, 2, 6], labels=['None', 'Low', 'High'])\n",
    "        # Cost-related features\n",
    "        X['ChargePerMonthRatio'] = X['MonthlyCharges'] / X['tenure'].replace(0, 1)\n",
    "        X['MonthlyCharges_group'] = pd.cut(X['MonthlyCharges'], bins=[0, 40, 70, 100, np.inf], \n",
    "                                           labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "        # Interaction terms\n",
    "        X['Fiber_NoTechSupport'] = ((X['InternetService'] == 'Fiber optic') & (X['TechSupport'] == 'No')).astype(int)\n",
    "        X['FiberOptic_StreamingTV'] = ((X['InternetService'] == 'Fiber optic') & (X['StreamingTV'] == 'Yes')).astype(int)\n",
    "        X['Senior_Contract'] = ((X['SeniorCitizen'] == 1) & (X['Contract'] == 'Month-to-month')).astype(int)\n",
    "        X['Contract_Duration_Ratio'] = X['tenure'] / X['Contract'].map(self.contract_durations)\n",
    "        X['M2M_ElectronicCheck'] = ((X['Contract'] == 'Month-to-month') & \n",
    "                                  (X['PaymentMethod'] == 'Electronic check')).astype(int)\n",
    "        X['IsMonthToMonth'] = (X['Contract'] == 'Month-to-month').astype(int)\n",
    "\n",
    "        obj_cols = X.select_dtypes(include='object').columns\n",
    "        binary_cols = [col for col in obj_cols if X[col].nunique() == 2]\n",
    "        for col in binary_cols:\n",
    "            # Debug print to inspect values\n",
    "            print(f\"{col} before mapping: {X[col].unique()}\")\n",
    "            X[col] = X[col].replace([np.inf, -np.inf], np.nan).fillna('No')  # Handle inf and NaN\n",
    "            X[col] = X[col].map({'No': 0, 'Yes': 1}).astype('Int64')  # Use nullable integer\n",
    "            print(f\"{col} after mapping: {X[col].unique()}\")\n",
    "\n",
    "        X.drop(columns=['TotalCharges', 'MonthlyCharges', 'tenure', 'SeniorCitizen', 'PaymentMethod', 'PhoneService', 'gender'], inplace=True)\n",
    "        self.output_columns_ = X.columns.tolist()\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.output_columns_\n",
    "\n",
    "# Step 1: Load the saved pipeline\n",
    "pipeline = joblib.load('feature_pipeline.joblib')\n",
    "\n",
    "# Step 2: Load the cleaned dataset\n",
    "data = pd.read_csv('../data/cleaned_data.csv')\n",
    "\n",
    "# Step 3: Transform the data\n",
    "X = data.drop(columns=['Churn'])  # Features\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "y = data['Churn']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f665b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column length mismatch: 25 vs. 15",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m feature_gen = pipeline.named_steps[\u001b[33m'\u001b[39m\u001b[33mfeature_gen\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m feature_names = feature_gen.get_feature_names_out()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_transformed_df = pd.DataFrame.sparse.from_spmatrix(X_transformed, columns=feature_names)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Step 4: View the first few rows\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(X_transformed_df.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/datasci/lib/python3.12/site-packages/pandas/core/arrays/sparse/accessor.py:285\u001b[39m, in \u001b[36mSparseFrameAccessor.from_spmatrix\u001b[39m\u001b[34m(cls, data, index, columns)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[32m    284\u001b[39m data = data.tocsc()\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m index, columns = \u001b[38;5;28mcls\u001b[39m._prep_index(data, index, columns)\n\u001b[32m    286\u001b[39m n_rows, n_columns = data.shape\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# We need to make sure indices are sorted, as we create\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# IntIndex with no input validation (i.e. check_integrity=False ).\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Indices may already be sorted in scipy in which case this adds\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# a small overhead.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/datasci/lib/python3.12/site-packages/pandas/core/arrays/sparse/accessor.py:411\u001b[39m, in \u001b[36mSparseFrameAccessor._prep_index\u001b[39m\u001b[34m(data, index, columns)\u001b[39m\n\u001b[32m    408\u001b[39m     columns = ensure_index(columns)\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != K:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn length mismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vs. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) != N:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex length mismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m vs. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Column length mismatch: 25 vs. 15"
     ]
    }
   ],
   "source": [
    "feature_gen = pipeline.named_steps['feature_gen']\n",
    "feature_names = feature_gen.get_feature_names_out()\n",
    "X_transformed_df = pd.DataFrame.sparse.from_spmatrix(X_transformed, columns=feature_names)\n",
    "\n",
    "# Step 4: View the first few rows\n",
    "print(X_transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e3922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
